---- data exception ----

llama_perf_sampler_print:    sampling time =       2.02 ms /    52 runs   (    0.04 ms per token, 25768.09 tokens per second)
llama_perf_context_print:        load time =   48600.01 ms
llama_perf_context_print: prompt eval time =     241.46 ms /    15 tokens (   16.10 ms per token,    62.12 tokens per second)
llama_perf_context_print:        eval time =    3395.74 ms /    36 runs   (   94.33 ms per token,    10.60 tokens per second)
llama_perf_context_print:       total time =    3646.20 ms /    51 tokens

llama_perf_sampler_print:    sampling time =       7.56 ms /   143 runs   (    0.05 ms per token, 18905.34 tokens per second)
llama_perf_context_print:        load time =   10641.36 ms
llama_perf_context_print: prompt eval time =     195.71 ms /    15 tokens (   13.05 ms per token,    76.64 tokens per second)
llama_perf_context_print:        eval time =   12112.59 ms /   127 runs   (   95.37 ms per token,    10.48 tokens per second)
llama_perf_context_print:       total time =   12337.38 ms /   142 tokens

llama_perf_sampler_print:    sampling time =       6.69 ms /   142 runs   (    0.05 ms per token, 21225.71 tokens per second)
llama_perf_context_print:        load time =   10560.23 ms
llama_perf_context_print: prompt eval time =     237.17 ms /    14 tokens (   16.94 ms per token,    59.03 tokens per second)
llama_perf_context_print:        eval time =   11379.48 ms /   127 runs   (   89.60 ms per token,    11.16 tokens per second)
llama_perf_context_print:       total time =   11645.78 ms /   141 tokens

llama_perf_sampler_print:    sampling time =       0.92 ms /    29 runs   (    0.03 ms per token, 31624.86 tokens per second)
llama_perf_context_print:        load time =   10601.48 ms
llama_perf_context_print: prompt eval time =     197.23 ms /    14 tokens (   14.09 ms per token,    70.98 tokens per second)
llama_perf_context_print:        eval time =    1421.65 ms /    14 runs   (  101.55 ms per token,     9.85 tokens per second)
llama_perf_context_print:       total time =    1624.50 ms /    28 tokens

llama_perf_sampler_print:    sampling time =       7.58 ms /   140 runs   (    0.05 ms per token, 18457.48 tokens per second)
llama_perf_context_print:        load time =   10534.93 ms
llama_perf_context_print: prompt eval time =     211.54 ms /    14 tokens (   15.11 ms per token,    66.18 tokens per second)
llama_perf_context_print:        eval time =   11339.32 ms /   125 runs   (   90.71 ms per token,    11.02 tokens per second)
llama_perf_context_print:       total time =   11579.75 ms /   139 tokens

llama_perf_sampler_print:    sampling time =       1.90 ms /    49 runs   (    0.04 ms per token, 25735.29 tokens per second)
llama_perf_context_print:        load time =   10539.58 ms
llama_perf_context_print: prompt eval time =     147.87 ms /    16 tokens (    9.24 ms per token,   108.20 tokens per second)
llama_perf_context_print:        eval time =    3066.40 ms /    32 runs   (   95.83 ms per token,    10.44 tokens per second)
llama_perf_context_print:       total time =    3222.77 ms /    48 tokens

llama_perf_sampler_print:    sampling time =       0.83 ms /    30 runs   (    0.03 ms per token, 35928.14 tokens per second)
llama_perf_context_print:        load time =   10528.28 ms
llama_perf_context_print: prompt eval time =     225.52 ms /    14 tokens (   16.11 ms per token,    62.08 tokens per second)
llama_perf_context_print:        eval time =    1383.55 ms /    15 runs   (   92.24 ms per token,    10.84 tokens per second)
llama_perf_context_print:       total time =    1614.06 ms /    29 tokens

llama_perf_sampler_print:    sampling time =       8.10 ms /   143 runs   (    0.06 ms per token, 17645.61 tokens per second)
llama_perf_context_print:        load time =   10539.00 ms
llama_perf_context_print: prompt eval time =     215.07 ms /    15 tokens (   14.34 ms per token,    69.75 tokens per second)
llama_perf_context_print:        eval time =   11947.93 ms /   127 runs   (   94.08 ms per token,    10.63 tokens per second)
llama_perf_context_print:       total time =   12196.73 ms /   142 tokens

llama_perf_sampler_print:    sampling time =       2.51 ms /    59 runs   (    0.04 ms per token, 23496.61 tokens per second)
llama_perf_context_print:        load time =   10525.28 ms
llama_perf_context_print: prompt eval time =     158.95 ms /    16 tokens (    9.93 ms per token,   100.66 tokens per second)
llama_perf_context_print:        eval time =    3876.78 ms /    42 runs   (   92.30 ms per token,    10.83 tokens per second)
llama_perf_context_print:       total time =    4046.59 ms /    58 tokens