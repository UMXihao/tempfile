llama_perf_sampler_print:    sampling time =       4.34 ms /   153 runs   (    0.03 ms per token, 35245.34 tokens per second)
llama_perf_context_print:        load time =   19659.34 ms
llama_perf_context_print: prompt eval time =      39.55 ms /    25 tokens (    1.58 ms per token,   632.05 tokens per second)
llama_perf_context_print:        eval time =    3403.95 ms /   127 runs   (   26.80 ms per token,    37.31 tokens per second)
llama_perf_context_print:       total time =    3459.62 ms /   152 tokens

llama_perf_sampler_print:    sampling time =       4.13 ms /   152 runs   (    0.03 ms per token, 36777.16 tokens per second)
llama_perf_context_print:        load time =   19558.32 ms
llama_perf_context_print: prompt eval time =      36.32 ms /    24 tokens (    1.51 ms per token,   660.76 tokens per second)
llama_perf_context_print:        eval time =    3399.78 ms /   127 runs   (   26.77 ms per token,    37.36 tokens per second)
llama_perf_context_print:       total time =    3450.55 ms /   151 tokens

llama_perf_sampler_print:    sampling time =       4.43 ms /   154 runs   (    0.03 ms per token, 34755.13 tokens per second)
llama_perf_context_print:        load time =   19520.24 ms
llama_perf_context_print: prompt eval time =      36.64 ms /    26 tokens (    1.41 ms per token,   709.57 tokens per second)
llama_perf_context_print:        eval time =    3402.28 ms /   127 runs   (   26.79 ms per token,    37.33 tokens per second)
llama_perf_context_print:       total time =    3455.64 ms /   153 tokens

llama_perf_sampler_print:    sampling time =       3.27 ms /   130 runs   (    0.03 ms per token, 39791.86 tokens per second)
llama_perf_context_print:        load time =   19584.47 ms
llama_perf_context_print: prompt eval time =      36.32 ms /    25 tokens (    1.45 ms per token,   688.38 tokens per second)
llama_perf_context_print:        eval time =    2775.91 ms /   104 runs   (   26.69 ms per token,    37.47 tokens per second)
llama_perf_context_print:       total time =    2824.17 ms /   129 tokens

llama_perf_sampler_print:    sampling time =       4.25 ms /   153 runs   (    0.03 ms per token, 36000.00 tokens per second)
llama_perf_context_print:        load time =   19498.06 ms
llama_perf_context_print: prompt eval time =      36.16 ms /    25 tokens (    1.45 ms per token,   691.47 tokens per second)
llama_perf_context_print:        eval time =    3398.78 ms /   127 runs   (   26.76 ms per token,    37.37 tokens per second)
llama_perf_context_print:       total time =    3451.53 ms /   152 tokens

llama_perf_sampler_print:    sampling time =       4.06 ms /   153 runs   (    0.03 ms per token, 37694.01 tokens per second)
llama_perf_context_print:        load time =   19589.15 ms
llama_perf_context_print: prompt eval time =      36.40 ms /    25 tokens (    1.46 ms per token,   686.89 tokens per second)
llama_perf_context_print:        eval time =    3422.97 ms /   127 runs   (   26.95 ms per token,    37.10 tokens per second)
llama_perf_context_print:       total time =    3474.10 ms /   152 tokens

llama_perf_sampler_print:    sampling time =       3.92 ms /   152 runs   (    0.03 ms per token, 38825.03 tokens per second)
llama_perf_context_print:        load time =   19556.90 ms
llama_perf_context_print: prompt eval time =      34.86 ms /    24 tokens (    1.45 ms per token,   688.43 tokens per second)
llama_perf_context_print:        eval time =    3404.89 ms /   127 runs   (   26.81 ms per token,    37.30 tokens per second)
llama_perf_context_print:       total time =    3453.75 ms /   151 tokens

llama_perf_sampler_print:    sampling time =       3.88 ms /   155 runs   (    0.03 ms per token, 39958.75 tokens per second)
llama_perf_context_print:        load time =   19542.84 ms
llama_perf_context_print: prompt eval time =      36.48 ms /    27 tokens (    1.35 ms per token,   740.15 tokens per second)
llama_perf_context_print:        eval time =    3403.17 ms /   127 runs   (   26.80 ms per token,    37.32 tokens per second)
llama_perf_context_print:       total time =    3453.59 ms /   154 tokens

llama_perf_sampler_print:    sampling time =       3.87 ms /   153 runs   (    0.03 ms per token, 39545.10 tokens per second)
llama_perf_context_print:        load time =   19552.53 ms
llama_perf_context_print: prompt eval time =      36.38 ms /    25 tokens (    1.46 ms per token,   687.27 tokens per second)
llama_perf_context_print:        eval time =    3416.73 ms /   127 runs   (   26.90 ms per token,    37.17 tokens per second)
llama_perf_context_print:       total time =    3466.99 ms /   152 tokens

llama_perf_sampler_print:    sampling time =       4.02 ms /   154 runs   (    0.03 ms per token, 38308.46 tokens per second)
llama_perf_context_print:        load time =   19560.61 ms
llama_perf_context_print: prompt eval time =      36.38 ms /    26 tokens (    1.40 ms per token,   714.76 tokens per second)
llama_perf_context_print:        eval time =    3402.29 ms /   127 runs   (   26.79 ms per token,    37.33 tokens per second)
llama_perf_context_print:       total time =    3452.68 ms /   153 tokens